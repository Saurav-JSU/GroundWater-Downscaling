{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1d3a9c8",
   "metadata": {},
   "source": [
    "# 0. Data Exploration and Quality Check\n",
    "\n",
    "This notebook performs exploratory checks on the raw datasets to evaluate data availability, quality, and alignment for GRACE downscaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398d0833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from rasterio.plot import show\n",
    "from datetime import datetime\n",
    "from matplotlib.dates import DateFormatter\n",
    "%matplotlib inline\n",
    "\n",
    "#plt.style.use('seaborn-whitegrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8426b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR = \"../data/raw\"\n",
    "DATASETS = {\n",
    "    \"GRACE\": os.path.join(RAW_DIR, \"grace\"),\n",
    "    \"GLDAS\": os.path.join(RAW_DIR, \"gldas\"),\n",
    "    \"CHIRPS\": os.path.join(RAW_DIR, \"chirps\"),\n",
    "    \"MODIS_LC\": os.path.join(RAW_DIR, \"modis_land_cover\"),\n",
    "    \"DEM\": os.path.join(RAW_DIR, \"usgs_dem\"),\n",
    "    \"TERRACLIMATE\": os.path.join(RAW_DIR, \"terraclimate\"),\n",
    "    \"WELLS\": os.path.join(RAW_DIR, \"usgs_well_data\", \"monthly_groundwater_anomalies.csv\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7d1fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grace_files = sorted(glob.glob(os.path.join(DATASETS[\"GRACE\"], \"*.tif\")))\n",
    "print(f\"Found {len(grace_files)} GRACE files. Example file: {grace_files[0]}\")\n",
    "\n",
    "with rasterio.open(grace_files[0]) as src:\n",
    "    grace_data = src.read(1)\n",
    "    grace_meta = src.meta\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.title(\"Sample GRACE Anomaly\")\n",
    "show(grace_data, cmap=\"coolwarm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f589bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "chirps_files = sorted(glob.glob(os.path.join(DATASETS[\"CHIRPS\"], \"*.tif\")))\n",
    "print(f\"Found {len(chirps_files)} CHIRPS files. Example: {chirps_files[0]}\")\n",
    "\n",
    "with rasterio.open(chirps_files[0]) as src:\n",
    "    chirps_data = src.read(1)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.title(\"Sample CHIRPS Monthly Precipitation\")\n",
    "show(chirps_data, cmap=\"Blues\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a04ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wells_df = pd.read_csv(DATASETS[\"WELLS\"], index_col=\"Date\", parse_dates=True)\n",
    "print(f\"Loaded well data with shape: {wells_df.shape}\")\n",
    "wells_df.iloc[:, :3].plot(figsize=(10, 4), title=\"Sample USGS Groundwater Anomalies\")\n",
    "plt.ylabel(\"Anomaly (m)\")\n",
    "plt.xlabel(\"Time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae20ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with rasterio.open(\"../data/raw/grace/20030131_20030227.tif\") as src:\n",
    "    data = src.read(1)\n",
    "    plt.imshow(data, cmap='viridis')\n",
    "    plt.colorbar(label='TWSA')\n",
    "    plt.title(\"GRACE TWS Anomaly\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77067c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def extract_dates_from_filenames(filelist):\n",
    "    dates = []\n",
    "    for f in filelist:\n",
    "        fname = os.path.basename(f)\n",
    "        digits = ''.join(c for c in fname if c.isdigit())\n",
    "        if len(digits) >= 6:\n",
    "            try:\n",
    "                dates.append(datetime.strptime(digits[:6], \"%Y%m\"))\n",
    "            except:\n",
    "                continue\n",
    "    return sorted(dates)\n",
    "\n",
    "def generate_dates_for_indexed_files(filelist, start=\"2003-01\"):\n",
    "    start_date = datetime.strptime(start, \"%Y-%m\")\n",
    "    return [start_date + relativedelta(months=i) for i in range(len(filelist))]\n",
    "\n",
    "# Determine per dataset\n",
    "date_summary = {}\n",
    "\n",
    "# GRACE: use date from filenames\n",
    "grace_files = sorted(glob.glob(os.path.join(DATASETS[\"GRACE\"], \"*.tif\")))\n",
    "date_summary[\"GRACE\"] = extract_dates_from_filenames(grace_files)\n",
    "\n",
    "# CHIRPS: use indexed fallback\n",
    "chirps_files = sorted(glob.glob(os.path.join(DATASETS[\"CHIRPS\"], \"*.tif\")), key=lambda x: int(os.path.basename(x).split(\".\")[0]))\n",
    "date_summary[\"CHIRPS\"] = generate_dates_for_indexed_files(chirps_files)\n",
    "\n",
    "# Print results\n",
    "for k, v in date_summary.items():\n",
    "    if len(v) > 0:\n",
    "        print(f\"{k}: {len(v)} months from {v[0]} to {v[-1]}\")\n",
    "    else:\n",
    "        print(f\"{k}: ⚠️ No dates found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1101ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=pd.date_range(\"2003-01\", \"2022-12\", freq=\"MS\"))\n",
    "for k in date_summary:\n",
    "    df[k] = df.index.isin(date_summary[k]).astype(int)\n",
    "\n",
    "df.plot(kind=\"bar\", stacked=True, figsize=(12, 4), width=1, title=\"Data Availability Calendar (2003–2022)\")\n",
    "plt.ylabel(\"Availability\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.xticks([])\n",
    "plt.legend(loc='upper right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7f6c34",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- ✅ Loaded and visualized samples from GRACE, CHIRPS, and USGS wells.\n",
    "- ✅ Verified time coverage and monthly availability from 2003 to 2022.\n",
    "- ⏭️ Next: Preprocess datasets to anomalies (for RF training) in `features.py`:\n",
    "  - Normalize dynamic datasets (monthly climatology subtraction)\n",
    "  - Normalize or encode static datasets\n",
    "  - Align all to common grid and time axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab40264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "ds = xr.open_dataset(\"../data/processed/feature_stack.nc\")\n",
    "print(ds)\n",
    "print(ds.feature.values[:10])  # Check naming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2631a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "ds = xr.open_dataset(\"../data/processed/feature_stack.nc\")\n",
    "\n",
    "# Select and plot one feature\n",
    "da = ds.features.sel(feature=\"chirps_2010-05\")\n",
    "da.plot()\n",
    "plt.title(\"CHIRPS - May 2010\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02309961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "ds = xr.open_dataset(\"../data/processed/feature_stack.nc\")\n",
    "print(ds)\n",
    "\n",
    "print(\"\\nFeature Names Sample:\")\n",
    "print(ds.feature.values[:10])\n",
    "\n",
    "print(\"\\nTotal Features:\", len(ds.feature))\n",
    "print(\"Dimensions:\", ds.dims)\n",
    "print(\"Variable Names:\", list(ds.data_vars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1f2edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Load the NetCDF file\n",
    "path = \"../data/processed/feature_stack.nc\"\n",
    "ds = xr.open_dataset(path)\n",
    "\n",
    "print(\"\\n📦 Feature Stack Summary\")\n",
    "print(\"Shape:\", ds.features.shape)\n",
    "\n",
    "# Count features\n",
    "all_features = ds.feature.values\n",
    "num_features = len(all_features)\n",
    "print(\"Total features:\", num_features)\n",
    "\n",
    "# Check temporal vs static\n",
    "temporal = [f for f in all_features if any(str(y) in f for y in range(2002, 2025))]\n",
    "static = [f for f in all_features if f not in temporal]\n",
    "\n",
    "print(\"\\n📆 Temporal features:\", len(temporal))\n",
    "print(\"🧱 Static features:\", len(static))\n",
    "\n",
    "# Feature group summary\n",
    "print(\"\\n📊 Feature counts by dataset prefix:\")\n",
    "from collections import Counter\n",
    "prefix_counts = Counter([f.split(\"_\")[0] for f in temporal + static])\n",
    "for k, v in prefix_counts.items():\n",
    "    print(f\"  - {k}: {v}\")\n",
    "\n",
    "# NaN summary\n",
    "nan_ratio = float(np.isnan(ds.features.data).sum()) / ds.features.data.size\n",
    "print(f\"\\n🧪 NaN fraction: {nan_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def generate_index_based_timestamp_map(start_date=\"2003-01\", num_months=240):\n",
    "    \"\"\"Generate a mapping: '0.tif' -> '2003-01', ..., '239.tif' -> '2022-12'\"\"\"\n",
    "    start = datetime.strptime(start_date, \"%Y-%m\")\n",
    "    timestamp_map = {\n",
    "        f\"{i}.tif\": (start.replace(day=1) if i == 0 else (start.replace(day=1) + pd.DateOffset(months=i))).strftime(\"%Y-%m\")\n",
    "        for i in range(num_months)\n",
    "    }\n",
    "    return timestamp_map\n",
    "\n",
    "def validate_file_timestamps(folder_path, expected_count=240, start_date=\"2003-01\"):\n",
    "    timestamp_map = generate_index_based_timestamp_map(start_date=start_date, num_months=expected_count)\n",
    "    files = sorted(f for f in os.listdir(folder_path) if f.endswith(\".tif\") and f.split('.')[0].isdigit())\n",
    "    \n",
    "    missing = [f\"{i}.tif\" for i in range(expected_count) if f\"{i}.tif\" not in files]\n",
    "    extra = [f for f in files if f not in timestamp_map]\n",
    "    aligned = [f for f in files if f in timestamp_map]\n",
    "\n",
    "    print(f\"\\n📂 Checking folder: {folder_path}\")\n",
    "    print(f\"✅ Total expected: {expected_count}\")\n",
    "    print(f\"✅ Found: {len(files)}\")\n",
    "    print(f\"✅ Aligned with timestamp map: {len(aligned)}\")\n",
    "    print(f\"❌ Missing files: {len(missing)}\")\n",
    "    if missing:\n",
    "        print(f\"   ⤷ Sample missing: {missing[:5]}\")\n",
    "    if extra:\n",
    "        print(f\"❌ Extra/unmapped files found: {extra[:5]}\")\n",
    "\n",
    "    return {\n",
    "        \"aligned_files\": aligned,\n",
    "        \"missing_files\": missing,\n",
    "        \"extra_files\": extra,\n",
    "        \"timestamp_map\": timestamp_map\n",
    "    }\n",
    "\n",
    "\n",
    "results = validate_file_timestamps(\"../data/raw/gldas/SoilMoi0_10cm_inst\", start_date=\"2003-01\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a6dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Expected timeline: 240 months from Jan 2003 to Dec 2022\n",
    "expected_timestamps = [\n",
    "    datetime(2003 + (i // 12), (i % 12) + 1, 1).strftime(\"%Y-%m\")\n",
    "    for i in range(240)\n",
    "]\n",
    "\n",
    "# Root folder for GLDAS data\n",
    "root_dir = Path(\"../data/raw/\")\n",
    "\n",
    "# Check each subfolder\n",
    "for subfolder in sorted(root_dir.iterdir()):\n",
    "    if not subfolder.is_dir():\n",
    "        continue\n",
    "\n",
    "    tif_files = sorted([f for f in subfolder.glob(\"*.tif\") if f.is_file()])\n",
    "    n_files = len(tif_files)\n",
    "\n",
    "    print(f\"\\n📂 Checking folder: {subfolder}\")\n",
    "    print(f\"✅ Total expected: {len(expected_timestamps)}\")\n",
    "    print(f\"{'✅' if n_files == 240 else '❌'} Found: {n_files}\")\n",
    "\n",
    "    aligned = True\n",
    "    for i, tif in enumerate(tif_files):\n",
    "        expected_name = f\"{i}.tif\"\n",
    "        if tif.name != expected_name:\n",
    "            aligned = False\n",
    "            break\n",
    "\n",
    "    if aligned:\n",
    "        print(f\"✅ Aligned with timestamp map: {n_files}\")\n",
    "    else:\n",
    "        print(f\"❌ Aligned with timestamp map: 0\")\n",
    "\n",
    "    missing = 240 - n_files\n",
    "    print(f\"{'❌' if missing else '✅'} Missing files: {missing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f69940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Set root directories\n",
    "root_dir = Path(\"../data/raw\")\n",
    "folders_to_check = [\n",
    "    \"gldas/Evap_tavg\",\n",
    "    \"gldas/SWE_inst\",\n",
    "    \"gldas/SoilMoi0_10cm_inst\",\n",
    "    \"gldas/SoilMoi10_40cm_inst\",\n",
    "    \"gldas/SoilMoi40_100cm_inst\",\n",
    "    \"gldas/SoilMoi100_200cm_inst\",\n",
    "    \"chirps\",\n",
    "    \"grace\",\n",
    "    \"modis_land_cover\",\n",
    "    \"openlandmap\",\n",
    "    \"terraclimate/aet\",\n",
    "    \"terraclimate/def\",\n",
    "    \"terraclimate/tmmx\",\n",
    "    \"terraclimate/tmmn\",\n",
    "    \"terraclimate/pr\",\n",
    "    \"usgs_dem\",\n",
    "    \"usgs_well_data\"\n",
    "]\n",
    "\n",
    "# Generate expected 240 timestamps (2003-01 to 2022-12)\n",
    "expected_dates = [datetime(2003, 1, 1).replace(month=((i % 12) + 1), year=2003 + i // 12).strftime('%Y-%m') for i in range(240)]\n",
    "\n",
    "print(\"📂 Validating Timestamp Alignment\\n\")\n",
    "for folder in folders_to_check:\n",
    "    folder_path = root_dir / folder\n",
    "    if not folder_path.exists():\n",
    "        print(f\"📂 Folder not found: {folder}\")\n",
    "        continue\n",
    "\n",
    "    files = sorted(folder_path.glob(\"*.tif\"), key=lambda f: int(f.stem) if f.stem.isdigit() else float('inf'))\n",
    "    found = len(files)\n",
    "    aligned = 0\n",
    "    missing = max(0, 240 - found)\n",
    "\n",
    "    # For numeric file names like 0.tif, 1.tif...\n",
    "    file_ids = [f.stem for f in files]\n",
    "    if all(fid.isdigit() for fid in file_ids):\n",
    "        aligned = min(240, found)  # Assume alignment by index\n",
    "    else:\n",
    "        aligned = sum(any(d.replace(\"-\", \"\") in fname for fname in file_ids) for d in expected_dates)\n",
    "\n",
    "    print(f\"📂 Checking folder: {folder_path}\")\n",
    "    print(f\"✅ Total expected: 240\")\n",
    "    print(f\"{'✅' if found == 240 else '❌'} Found: {found}\")\n",
    "    print(f\"{'✅' if aligned == 240 else '❌'} Aligned with timestamp map: {aligned}\")\n",
    "    print(f\"{'✅' if missing == 0 else '❌'} Missing files: {missing}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01696ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def extract_grace_months_from_ranges(grace_dir):\n",
    "    months = []\n",
    "    for f in Path(grace_dir).glob(\"*.tif\"):\n",
    "        m = re.search(r'_(\\d{8})\\.tif$', f.name)  # extract second date\n",
    "        if m:\n",
    "            dt = datetime.strptime(m.group(1), \"%Y%m%d\")\n",
    "            ym = dt.strftime(\"%Y-%m\")\n",
    "            months.append(ym)\n",
    "    return sorted(set(months))\n",
    "\n",
    "# Run this\n",
    "grace_months = extract_grace_months_from_ranges(\"../data/raw/grace\")\n",
    "print(f\"✅ Valid GRACE months: {len(grace_months)}\")\n",
    "print(grace_months[:5], \"...\", grace_months[-5:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0528669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
